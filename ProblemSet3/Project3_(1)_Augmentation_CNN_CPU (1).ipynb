{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tbfz3zSXBt3H"
   },
   "source": [
    "# <p style=\"text-align: center;\">MIS 284N - Big Data and Distributed Programming</p>\n",
    "## <p style=\"text-align: center;\">Project 3 - Machine Learning using Tensorflow and Google Colab</p>\n",
    "## <p style=\"text-align: center;\">Total points: 100</p>\n",
    "## <p style=\"text-align: center;\">Due: Sunday, October 17th submitted via Canvas by 11:59 pm</p>\n",
    "\n",
    "This will be a in-class project done in teams of 2. \n",
    "\n",
    "In this Project, we will work with CIFAR10 image dataset. \n",
    "The starter code to download the database using keras is given below. \n",
    "Test the project on Google Colab running on a CPU, GPU and TPU\n",
    " \n",
    "\n",
    "# In every line of code, please write a comment to briefly explain what that line is doing.\n",
    "Your grades will be based on your understanding of the code you write! \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RnHTzAuvxxQT"
   },
   "source": [
    "# Task 1\n",
    "Convert the features in a form that can be given as input to tensorflow library/functions\n",
    "\n",
    "In this task you will perform data augmentation. That is, pre-process the data to make the model more robust. Experiment with data augmentation techniques like rotation, translation, horizontal-flip, scaling, ZCA whitening and histogram equalization. \n",
    "You can choose any two or more augmentation technique(s) of your choice. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "RfXRqFgivcVv"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from keras.callbacks import ModelCheckpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T9qrDetJJofS",
    "outputId": "e0f78376-278e-4e68-8e6d-119b65eddb1e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170500096/170498071 [==============================] - 4s 0us/step\n",
      "170508288/170498071 [==============================] - 4s 0us/step\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import cifar10\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NBd8Lsmevt4G",
    "outputId": "1f0150fe-bc39-4255-fac9-c579c93652c9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 32, 32, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AGtIK4Rxvwsd",
    "outputId": "c05e3605-2ab6-4367-ecea-37d4e68ff124"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MkCCXOk7vnbF",
    "outputId": "c099bbe5-6805-4d44-8c51-4df1cd33709f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K1UpFxU4vrjh",
    "outputId": "4fb6aafc-e3da-4fb7-91bc-0b41d8d1efb0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "s6PnpWlOv41n"
   },
   "outputs": [],
   "source": [
    "# Normalize data.\n",
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = x_test.astype('float32') / 255\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XKxKdyLlwzoq"
   },
   "outputs": [],
   "source": [
    "## Data Augmentation \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UDS-Mu3_v8he",
    "outputId": "cc05fd2f-7d4e-419b-e827-ed349be9a888"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6],\n",
       "       [9],\n",
       "       [9],\n",
       "       ...,\n",
       "       [9],\n",
       "       [1],\n",
       "       [1]], dtype=uint8)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M6c8xzloyoUD"
   },
   "source": [
    "# Task 2\n",
    "Try to build a Neural Network model, train on the features and report the accuracy.\n",
    "Report your observations on the time taken on CPU and GPU (with and without CuDNN kernel) \n",
    "\n",
    "\n",
    "\n",
    "1.   Create a CNN based model with 4 hidden layers with 64, 128, 256 and 512 units in each succesive layer. Use a 5x5 convolution kernel and change as necessary. (Use at least 2 augmentations on your input) \n",
    "2.   Create an LSTM based model with 1 LSTM layer with 256 units. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "kT7mmmvIwUAC"
   },
   "outputs": [],
   "source": [
    "##CNN Model\n",
    "\n",
    "def create_model():\n",
    "  model = tf.keras.models.Sequential()\n",
    "  model.add(tf.keras.layers.BatchNormalization(input_shape=x_train.shape[1:]))\n",
    "  model.add(tf.keras.layers.Conv2D(64, (5, 5), padding='same', activation='elu'))\n",
    "  model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "  model.add(tf.keras.layers.Dropout(0.25))\n",
    "\n",
    "  model.add(tf.keras.layers.BatchNormalization(input_shape=x_train.shape[1:]))\n",
    "  model.add(tf.keras.layers.Conv2D(128, (5, 5), padding='same', activation='elu'))\n",
    "  model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "  model.add(tf.keras.layers.Dropout(0.25))\n",
    "\n",
    "  model.add(tf.keras.layers.BatchNormalization(input_shape=x_train.shape[1:]))\n",
    "  model.add(tf.keras.layers.Conv2D(256, (5, 5), padding='same', activation='elu'))\n",
    "  model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "  model.add(tf.keras.layers.Dropout(0.25))\n",
    "\n",
    "  model.add(tf.keras.layers.BatchNormalization(input_shape=x_train.shape[1:]))\n",
    "  model.add(tf.keras.layers.Conv2D(512, (5, 5), padding='same', activation='elu'))\n",
    "  model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "  model.add(tf.keras.layers.Dropout(0.25))\n",
    "\n",
    "  model.add(tf.keras.layers.Flatten())\n",
    "  model.add(tf.keras.layers.Dense(512))\n",
    "  model.add(tf.keras.layers.Activation('elu'))\n",
    "  model.add(tf.keras.layers.Dropout(0.5))\n",
    "  model.add(tf.keras.layers.Dense(10))\n",
    "  model.add(tf.keras.layers.Activation('softmax'))\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "ztKAq7U_wcu6"
   },
   "outputs": [],
   "source": [
    "with tf.device('/device:GPU:0'):\n",
    "  model = create_model()\n",
    "  model.compile(\n",
    "      \n",
    "      optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3, ),\n",
    "      loss='sparse_categorical_crossentropy',\n",
    "      metrics=['sparse_categorical_accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wg2-y7OhyEZN",
    "outputId": "f4965ca2-c59b-4567-c2aa-a4766358a6b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using real-time data augmentation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/image_data_generator.py:337: UserWarning: This ImageDataGenerator specifies `zca_whitening`, which overrides setting of `featurewise_center`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12 µs, sys: 2 µs, total: 14 µs\n",
      "Wall time: 14.5 µs\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 215s 137ms/step - loss: 2.0032 - sparse_categorical_accuracy: 0.2829 - val_loss: 5.9812 - val_sparse_categorical_accuracy: 0.1057\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 210s 134ms/step - loss: 1.8070 - sparse_categorical_accuracy: 0.3515 - val_loss: 3.7938 - val_sparse_categorical_accuracy: 0.1261\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 209s 134ms/step - loss: 1.6958 - sparse_categorical_accuracy: 0.3945 - val_loss: 4.1778 - val_sparse_categorical_accuracy: 0.1167\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 211s 134ms/step - loss: 1.6187 - sparse_categorical_accuracy: 0.4242 - val_loss: 5.4999 - val_sparse_categorical_accuracy: 0.1165\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 215s 138ms/step - loss: 1.5475 - sparse_categorical_accuracy: 0.4516 - val_loss: 4.0363 - val_sparse_categorical_accuracy: 0.0999\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 210s 134ms/step - loss: 1.5008 - sparse_categorical_accuracy: 0.4712 - val_loss: 3.9469 - val_sparse_categorical_accuracy: 0.0987\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 203s 130ms/step - loss: 1.4640 - sparse_categorical_accuracy: 0.4892 - val_loss: 4.4289 - val_sparse_categorical_accuracy: 0.0987\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 205s 131ms/step - loss: 1.4227 - sparse_categorical_accuracy: 0.5046 - val_loss: 2.7950 - val_sparse_categorical_accuracy: 0.1025\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 206s 131ms/step - loss: 1.3890 - sparse_categorical_accuracy: 0.5153 - val_loss: 4.9120 - val_sparse_categorical_accuracy: 0.1000\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 211s 135ms/step - loss: 1.3581 - sparse_categorical_accuracy: 0.5270 - val_loss: 6.6925 - val_sparse_categorical_accuracy: 0.1021\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    }
   ],
   "source": [
    "print('Using real-time data augmentation.')\n",
    "print(\"CNN with GPU\")\n",
    "# Training parameters\n",
    "batch_size = 32  # orig paper trained all networks with batch_size=128\n",
    "epochs = 10\n",
    "data_augmentation = True\n",
    "num_classes = 10\n",
    "\n",
    "\n",
    "# Prepare model model saving directory.\n",
    "filepath = 'cifar10.h5'\n",
    "\n",
    "# Prepare callbacks for model saving and for learning rate adjustment.\n",
    "checkpoint = ModelCheckpoint(filepath=filepath,\n",
    "                             monitor='val_acc',\n",
    "                             verbose=1,\n",
    "                             save_best_only=True)\n",
    "callbacks = [checkpoint]\n",
    "with tf.device('/device:GPU:0'):\n",
    "  # This will do preprocessing and realtime data augmentation:\n",
    "  datagen = ImageDataGenerator(\n",
    "      \n",
    "      # set input mean to 0 over the dataset\n",
    "      featurewise_center=False,\n",
    "      # set each sample mean to 0\n",
    "      samplewise_center=False,\n",
    "      # divide inputs by std of dataset\n",
    "      featurewise_std_normalization=False,\n",
    "      # divide each input by its std\n",
    "      samplewise_std_normalization=False,\n",
    "      # apply ZCA whitening\n",
    "      zca_whitening=True,\n",
    "      # epsilon for ZCA whitening\n",
    "      zca_epsilon=1e-06,\n",
    "      # randomly rotate images in the range (deg 0 to 180)\n",
    "      rotation_range=180,\n",
    "      # randomly shift images horizontally\n",
    "      width_shift_range=0.1,\n",
    "      # randomly shift images vertically\n",
    "      height_shift_range=0.1,\n",
    "      # set range for random shear\n",
    "      shear_range=0.2,\n",
    "      # set range for random zoom\n",
    "      zoom_range=0.2,\n",
    "      # set range for random channel shifts\n",
    "      #channel_shift_range=0.,\n",
    "      # set mode for filling points outside the input boundaries\n",
    "      fill_mode='nearest',\n",
    "      # value used for fill_mode = \"constant\"\n",
    "      cval=0.,\n",
    "      # randomly flip images\n",
    "      horizontal_flip=True,\n",
    "      # randomly flip images\n",
    "      vertical_flip=False,\n",
    "      # set rescaling factor (applied before any other transformation)\n",
    "      rescale=None,\n",
    "      # set function that will be applied on each input\n",
    "      preprocessing_function=None,\n",
    "      # image data format, either \"channels_first\" or \"channels_last\"\n",
    "      data_format=None,\n",
    "      # fraction of images reserved for validation (strictly between 0 and 1)\n",
    "      validation_split=0.0)\n",
    "\n",
    "  # Compute quantities required for featurewise normalization\n",
    "  # (std, mean, and principal components if ZCA whitening is applied).\n",
    "\n",
    "  datagen.fit(x_train)\n",
    "\n",
    "  %%time\n",
    "  import time\n",
    "  print(\"CNN GPU\")\n",
    "  start = time.time()\n",
    "\n",
    "  # Fit the model on the batches generated by datagen.flow().\n",
    "  model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "                      validation_data=(x_test, y_test),\n",
    "                      epochs=epochs, verbose=1, workers=4,\n",
    "                      callbacks=callbacks)\n",
    "  stop = time.time()\n",
    "  print(f\"Training time: {stop - start}s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n7ZZkBnDRZOa"
   },
   "outputs": [],
   "source": [
    "# Score trained model.\n",
    "scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3dAVUVIA9LQI"
   },
   "source": [
    "CNN On CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "drzdzbI0-q-8"
   },
   "outputs": [],
   "source": [
    "model_cpu = create_model()\n",
    "model_cpu.compile(\n",
    "    \n",
    "      \n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3, ),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['sparse_categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oqm48sLs9OPa",
    "outputId": "cbc14829-6881-4331-c69e-4f0b53878ff9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using real-time data augmentation.\n",
      "CNN ON CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/image_data_generator.py:337: UserWarning: This ImageDataGenerator specifies `zca_whitening`, which overrides setting of `featurewise_center`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN on CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1563/1563 [==============================] - 1677s 1s/step - loss: 2.3770 - sparse_categorical_accuracy: 0.2158 - val_loss: 358.1837 - val_sparse_categorical_accuracy: 0.1167\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 2/5\n",
      "1563/1563 [==============================] - 1675s 1s/step - loss: 1.9005 - sparse_categorical_accuracy: 0.3147 - val_loss: 211.1394 - val_sparse_categorical_accuracy: 0.1008\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 3/5\n",
      "1563/1563 [==============================] - 1673s 1s/step - loss: 1.7511 - sparse_categorical_accuracy: 0.3751 - val_loss: 536.7241 - val_sparse_categorical_accuracy: 0.1000\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 4/5\n",
      "1563/1563 [==============================] - 1687s 1s/step - loss: 1.6533 - sparse_categorical_accuracy: 0.4110 - val_loss: 94.2833 - val_sparse_categorical_accuracy: 0.1024\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 5/5\n",
      " 929/1563 [================>.............] - ETA: 11:01 - loss: 1.5947 - sparse_categorical_accuracy: 0.4404"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print('Using real-time data augmentation.')\n",
    "print(\"CNN ON CPU\")\n",
    "# Training parameters\n",
    "batch_size = 32  # orig paper trained all networks with batch_size=128\n",
    "epochs = 5\n",
    "data_augmentation = True\n",
    "num_classes = 10\n",
    "\n",
    "\n",
    "# Prepare model model saving directory.\n",
    "filepath = 'cifar10.h5'\n",
    "\n",
    "# Prepare callbacks for model saving and for learning rate adjustment.\n",
    "# This will do preprocessing and realtime data augmentation:\n",
    "datagen = ImageDataGenerator(\n",
    "    \n",
    "      \n",
    "    # set input mean to 0 over the dataset\n",
    "    featurewise_center=False,\n",
    "    # set each sample mean to 0\n",
    "    samplewise_center=False,\n",
    "    # divide inputs by std of dataset\n",
    "    featurewise_std_normalization=False,\n",
    "    # divide each input by its std\n",
    "    samplewise_std_normalization=False,\n",
    "    # apply ZCA whitening\n",
    "    zca_whitening=True,\n",
    "    # epsilon for ZCA whitening\n",
    "    zca_epsilon=1e-06,\n",
    "    # randomly rotate images in the range (deg 0 to 180)\n",
    "    rotation_range=180,\n",
    "    # randomly shift images horizontally\n",
    "    width_shift_range=0.1,\n",
    "    # randomly shift images vertically\n",
    "    height_shift_range=0.1,\n",
    "    # set range for random shear\n",
    "    shear_range=0.2,\n",
    "    # set range for random zoom\n",
    "    zoom_range=0.2,\n",
    "    # set range for random channel shifts\n",
    "    #channel_shift_range=0.,\n",
    "    # set mode for filling points outside the input boundaries\n",
    "    fill_mode='nearest',\n",
    "    # value used for fill_mode = \"constant\"\n",
    "    cval=0.,\n",
    "    # randomly flip images\n",
    "    horizontal_flip=True,\n",
    "    # randomly flip images\n",
    "    vertical_flip=False,\n",
    "    # set rescaling factor (applied before any other transformation)\n",
    "    rescale=None,\n",
    "    # set function that will be applied on each input\n",
    "    preprocessing_function=None,\n",
    "    # image data format, either \"channels_first\" or \"channels_last\"\n",
    "    data_format=None,\n",
    "    # fraction of images reserved for validation (strictly between 0 and 1)\n",
    "    validation_split=0.0)\n",
    "\n",
    "# Compute quantities required for featurewise normalization\n",
    "# (std, mean, and principal components if ZCA whitening is applied).\n",
    "\n",
    "datagen.fit(x_train)\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "print(\"CNN on CPU\")\n",
    "\n",
    "# Fit the model on the batches generated by datagen.flow().\n",
    "model_cpu.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "                    validation_data=(x_test, y_test),\n",
    "                    epochs=epochs, verbose=1, workers=4,\n",
    "                    callbacks=callbacks)\n",
    "stop = time.time()\n",
    "print(f\"Training time CPU: {stop - start}s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mvl8qtBYxNbn"
   },
   "outputs": [],
   "source": [
    "# Score trained model.\n",
    "scores = model_cpu.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UigmhHzAwtSU"
   },
   "outputs": [],
   "source": [
    "model.save_weights('./cifar.h5', overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qOMqFeFxqV_j"
   },
   "source": [
    "# Task 3\n",
    "Run the LSTM solution in Task2 on a TPU and report the performance "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Project3 (1)_Augmentation_CNN_CPU.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
